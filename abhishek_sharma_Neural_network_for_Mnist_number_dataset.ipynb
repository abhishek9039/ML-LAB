{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "abhishek sharma  Neural_network_for_Mnist_number_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishek9039/ML-LAB/blob/main/abhishek_sharma_Neural_network_for_Mnist_number_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "zQvT7bhRzp4e"
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Loading-the-MNIST-dataset-in-Keras\" data-toc-modified-id=\"Loading-the-MNIST-dataset-in-Keras-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Loading the MNIST dataset in Keras</a></span></li><li><span><a href=\"#The-network-architecture\" data-toc-modified-id=\"The-network-architecture-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>The network architecture</a></span></li><li><span><a href=\"#The-compilation-step\" data-toc-modified-id=\"The-compilation-step-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>The compilation step</a></span></li><li><span><a href=\"#Preparing-the-image-data\" data-toc-modified-id=\"Preparing-the-image-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Preparing the image data</a></span></li><li><span><a href=\"#Preparing-the-labels\" data-toc-modified-id=\"Preparing-the-labels-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Preparing the labels</a></span></li><li><span><a href=\"#Training-and-Testing\" data-toc-modified-id=\"Training-and-Testing-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Training and Testing</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSee4zKUzp4i"
      },
      "source": [
        "# Loading the MNIST dataset in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a8IveFHzp4l"
      },
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQPmnZ8xzp4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d1cead5-7b4d-4d9b-f9d6-f7c5a66cb5a8"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnZfS9HYzp4z"
      },
      "source": [
        "- The images are encoded as Numpy arrays, and the labels are an array of digits, ranging from 0 to 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFdoffSmzp41",
        "outputId": "3d62b6d7-0cbf-4b37-b7c8-4e8893802e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD65nC-vzp45",
        "outputId": "9c938ed5-cdb1-4f1a-d361-50d0605b5e25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX9LpWNazp4_",
        "outputId": "efaf2bf8-8faa-45b9-9e27-c02c8368a505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG0L5p4Dzp5D",
        "outputId": "0c30bd8a-82eb-465c-98d4-93379887b6e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MimOH_Xnzp5I",
        "outputId": "18f5226d-3178-4de0-e326-c4fc22f36694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(test_labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EHR0v0Bzp5M",
        "outputId": "b54a7197-034b-484d-d40b-0bbbdffe840f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_labels"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Tp6nDRzp5R"
      },
      "source": [
        "Let's build the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxbJXg2Czp5T"
      },
      "source": [
        "# The network architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGCxNrDdzp5U"
      },
      "source": [
        "- The core building block of neural networks is the **layer**, a data-processing module that you can think of as a filter for data.\n",
        "    - Some data goes in, and it comes out in a more useful form.\n",
        "    - Layers extract **representations** (hopefully, meaningful for the data problem at hand) out of the data fed into them.\n",
        "    \n",
        "- Most of deep learning consists of chaining together simple layers that will implement a form of progressive **data distillation**.\n",
        "- A deep learning model is like a sieve for data-processing, made of a succession of increasingly refined data filters--**the layers**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyUqGjPTzp5V"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEVk0S9_zp5a"
      },
      "source": [
        "network = models.Sequential()\n",
        "# Dense(512) is a fully-connected layer with 512 hidden units.\n",
        "# in the first layer, you must specify the expected input data shape :\n",
        "# here, 28 X 28=784 -dimensional vectors.\n",
        "network.add(layers.Dense(32, activation='relu', input_shape=(28 * 28, )))\n",
        "network.add(layers.Dense(16, activation='tanh'))\n",
        "network.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af2c2tvKzp5f"
      },
      "source": [
        "- Our network consists of a sequence of two *Dense* layers, which are densely connected (also called *fully connected*) neural layers.\n",
        "- The second (and last) layer is a **10-way** *softmax* layer, which means it will return an array of **10** probability scores. Each score will be the probability that the current digit image belongs to one of our 10 digit classes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHbqJ-rWzp5g"
      },
      "source": [
        "# The compilation step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w0ne5wYzp5h"
      },
      "source": [
        "- To make the network ready for training, we need to pick three more things, as part of the **compilation** step:\n",
        " - **A loss function**-- How the network will be able to measure its performance on the training data, and thus how it will be able to steer itself in the right direction.\n",
        " - **An optimizer**--The mechanism through which the network will update itself based on the data it sees and its loss function.\n",
        " - **Metrics to monitor during training and testing**--Here, we will only care about accuracy (the fraction of the images that were correctly classified)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvSO-q9Ozp5i"
      },
      "source": [
        "network.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLHJqTLXzp5o"
      },
      "source": [
        "# Preparing the image data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajWKVl1-zp5q"
      },
      "source": [
        "Before training, we will preprocess the data by reshaping it into the shape the network expects and scaling it so that all values are in the $[0-1]$ interval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vMdz75Wzp5s"
      },
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255."
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4icW7vDgzp5w"
      },
      "source": [
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255."
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SHD8Vvhzp5z"
      },
      "source": [
        "# Preparing the labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA1YmuF1zp51"
      },
      "source": [
        "We also need to categorically encode the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh42ABtgzp58"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eCqlapJzp6A",
        "outputId": "6cddfd08-54b0-4914-ffc1-ae0dfff893c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_labels = to_categorical(train_labels)\n",
        "train_labels"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWXDQKNBzp6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec8170ab-9c85-442f-a3a0-18f0002ed8d2"
      },
      "source": [
        "test_labels = to_categorical(test_labels)\n",
        "test_labels"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csJ7yQVxzp6I"
      },
      "source": [
        "# Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-KLV-VIzp6K"
      },
      "source": [
        "We are now ready to train the network, which in Keras is done via a call to the network's fit method--we fit the model to its training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGWa7zXYzp6O",
        "outputId": "ad4382ec-5a43-4762-b6a5-cff0d3337d21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "network.fit(train_images, train_labels, epochs=24, batch_size=21)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/24\n",
            "2858/2858 [==============================] - 13s 4ms/step - loss: 0.3573 - accuracy: 0.9071\n",
            "Epoch 2/24\n",
            "2858/2858 [==============================] - 10s 4ms/step - loss: 0.1673 - accuracy: 0.9514\n",
            "Epoch 3/24\n",
            "2858/2858 [==============================] - 10s 3ms/step - loss: 0.1304 - accuracy: 0.9618\n",
            "Epoch 4/24\n",
            "2858/2858 [==============================] - 11s 4ms/step - loss: 0.1108 - accuracy: 0.9664\n",
            "Epoch 5/24\n",
            "2858/2858 [==============================] - 10s 4ms/step - loss: 0.0962 - accuracy: 0.9711\n",
            "Epoch 6/24\n",
            "2858/2858 [==============================] - 10s 4ms/step - loss: 0.0873 - accuracy: 0.9737\n",
            "Epoch 7/24\n",
            "2858/2858 [==============================] - 10s 4ms/step - loss: 0.0785 - accuracy: 0.9760\n",
            "Epoch 8/24\n",
            "2858/2858 [==============================] - 10s 3ms/step - loss: 0.0732 - accuracy: 0.9775\n",
            "Epoch 9/24\n",
            "2858/2858 [==============================] - 10s 3ms/step - loss: 0.0678 - accuracy: 0.9794\n",
            "Epoch 10/24\n",
            "2858/2858 [==============================] - 10s 3ms/step - loss: 0.0623 - accuracy: 0.9805\n",
            "Epoch 11/24\n",
            "2858/2858 [==============================] - 10s 4ms/step - loss: 0.0588 - accuracy: 0.9817\n",
            "Epoch 12/24\n",
            "2858/2858 [==============================] - 10s 3ms/step - loss: 0.0546 - accuracy: 0.9832\n",
            "Epoch 13/24\n",
            "2858/2858 [==============================] - 10s 3ms/step - loss: 0.0523 - accuracy: 0.9830\n",
            "Epoch 14/24\n",
            "2858/2858 [==============================] - 10s 3ms/step - loss: 0.0487 - accuracy: 0.9854\n",
            "Epoch 15/24\n",
            "2858/2858 [==============================] - 10s 3ms/step - loss: 0.0473 - accuracy: 0.9855\n",
            "Epoch 16/24\n",
            "2858/2858 [==============================] - 10s 3ms/step - loss: 0.0460 - accuracy: 0.9855\n",
            "Epoch 17/24\n",
            "2858/2858 [==============================] - 10s 4ms/step - loss: 0.0433 - accuracy: 0.9863\n",
            "Epoch 18/24\n",
            "2858/2858 [==============================] - 10s 3ms/step - loss: 0.0413 - accuracy: 0.9867\n",
            "Epoch 19/24\n",
            "2858/2858 [==============================] - 10s 3ms/step - loss: 0.0395 - accuracy: 0.9876\n",
            "Epoch 20/24\n",
            "2858/2858 [==============================] - 10s 4ms/step - loss: 0.0396 - accuracy: 0.9874\n",
            "Epoch 21/24\n",
            "2858/2858 [==============================] - 10s 3ms/step - loss: 0.0358 - accuracy: 0.9887\n",
            "Epoch 22/24\n",
            "2858/2858 [==============================] - 10s 4ms/step - loss: 0.0355 - accuracy: 0.9891\n",
            "Epoch 23/24\n",
            "2858/2858 [==============================] - 10s 4ms/step - loss: 0.0348 - accuracy: 0.9887\n",
            "Epoch 24/24\n",
            "2858/2858 [==============================] - 10s 4ms/step - loss: 0.0341 - accuracy: 0.9890\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a81140790>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heVasO26zp6V"
      },
      "source": [
        "- Two quantities are displayed during training:\n",
        "    - The loss of the network over the training data\n",
        "    - The accuracy of the network over the training data\n",
        "    \n",
        "- We quickly reach an accuracy of **$0.9886 (98.86\\%)$** on the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eDaNGAYzp6X"
      },
      "source": [
        "- Now let's check that the model performs well on the test set, too:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-UhmyTWzp6Y",
        "outputId": "ecb68bba-fbcd-4499-b140-92affea84279",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1388 - accuracy: 0.9646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omz-cZXLzp6d",
        "outputId": "a6c7c652-887a-4c8d-c72d-ae5572d96c98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Test Accuracy: {:.5f} '.format(test_acc))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.96460 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbIp64KFzp6g",
        "outputId": "6497d84b-574f-4668-f9e9-3c78a7f252b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_acc"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9646000266075134"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi5jDr-0zp6k"
      },
      "source": [
        "- The test-set accuracy turns out to be $97.780\\%$--that is quite a bit lower than the training set accuracy. This gap between training and test accuracy is an example of **overfitting**:the fact that the ML models tend to perform worse on new data than on their training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOu1IQW6zp6l",
        "outputId": "2652e9d6-e063-41c4-9dc0-9cb87f861511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(network, to_file='model.png')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOgAAAFgCAIAAAA+X6IuAAAABmJLR0QA/wD/AP+gvaeTAAAexklEQVR4nO3df1AT6f0H8M8mIT8WCCIX5LwAGvTk5Me1jkcR8Y7Wo5U6vTklalRU9Ojo2fbq3emlFYex9jzLgcWphToItdN2BhPxxl+t2p5U2s7Ajbb4EwGBAcWIQU2JkMiP8Hz/2O9lImAE3GTzxM/rL3af5Xk+u3nP5mHJbhhCCCBEG5HQBSA0ERhcRCUMLqISBhdRSeK6UFNT8+tf/1qoUhBy46OPPpo3b55z8Ykz7u3btysrK71ekv+rra2tra0VugqKVVZW3r5923WNZORGR44c8VY9L4ply5YBHtjnwDDMsDU4x0VUwuAiKmFwEZUwuIhKGFxEJQwuohIGF1EJg4uohMFFVMLgIiphcBGVMLiIShhcRCUMLqLS8wY3JycnODiYYZhLly7xUtDz++tf/xoSEnLy5EmhCxmf2tra1157TSQSMQwzZcqUTz/91GtDHz16VKPRMAzDMExERERWVpbXhp6wUT6POy5lZWVvv/32ypUreamGF5TecJ+cnHzjxo1FixadPXu2sbFx0qRJXhs6MzMzMzNzxowZ9+/f7+zs9Nq4z8MPpwqLFy/u7u7+wQ9+4OmB7HZ7SkqKp0fxEKqLB16CO/LT6S+I8vJys9ksdBUTRHXxMLHgEkIKCgpmzZolk8lCQkK2bdvm2upwOPLy8qKiohQKRWJiosFgAICSkpLAwECWZY8fP56RkaFUKtVqdUVFhfO3qqurk5KSWJZVKpUJCQlWq/VpXbn373//OyoqimGY3/72t88c9ze/+Y1cLg8PD9+0adPLL78sl8tTUlK++uorrvWDDz6QSqURERHc4o9+9KPAwECGYe7fvw8AW7Zs+fjjj1taWhiGmTFjxgQO4zP5WvH/+te/Zs+eHRISIpfLExISzp49CwA5OTnc5DgmJqaurg4A1q9fz7JsSEjIiRMn4Ckv4ueff86ybHBwsNls/vjjj1955ZXGxsbxHR3iguuUPEtubi7DMHv37rVYLDabrbi4GADq6uq41q1bt8pkssrKSovFsn37dpFIdOHCBe63AODcuXPd3d1ms3nBggWBgYH9/f2EkJ6eHqVSmZ+fb7fbOzs7ly5d2tXV5aYr97i76vbv3++s9mnjEkI2btwYGBhYX1//+PHj69evv/HGG8HBwbdu3eJaV69ePWXKFGfPBQUFAMDVRgjJzMyMiYl5Zj2EEK1Wq9Vqx7Ll9773PQCwWCzeLz4mJiYkJMRNbUeOHNm5c+fDhw8fPHiQnJwcFhbm7EosFt+5c8e55apVq06cOMH97D4PP/3pT/fv37906dIbN264GRoADAbDE2tcF8YSXJvNxrJsenq6cw13DuCCa7fbWZbV6XTOjWUy2ebNm52F2u12romLe3NzMyHk2rVrAHDq1CnXgdx05d6owR11XELIxo0bXV+tCxcuAMAvfvELbtFHguud4p8ZXFefffYZAJjNZkLIl19+CQCffvop19Td3T1z5szBwUEynjy4NzK4454qNDc322y2hQsXjtra2Nhos9ni4+O5RYVCERER0dDQMHJLqVQKAAMDAwCg0WjCw8OzsrJ27tzZ1tY23q7GxXXckebOncuy7POP4iG+U3xAQAAAOBwOAPjOd77z6quv/v73v+cSdvjwYZ1OJxaLwWMvIkxgjtvR0QEAKpVq1Nbe3l4A2LFjB/O19vZ2m83mvk+FQlFVVZWamrp7926NRqPT6ex2+8S6en4ymayrq8vTo3iIR4v/y1/+kpaWplKpZDLZJ5984lzPMMymTZtaW1vPnTsHAH/84x/fe+89rslzL+K4gyuXywGgr69v1FYu0EVFRa5n9Zqammd2GxcXd/LkSZPJpNfrDQZDYWHhhLt6HgMDA//73//UarVHR/EQTxT/z3/+s6ioCABu3bq1ZMmSiIiIr776qru7Oz8/33Wz7OxsuVxeVlbW2NioVCqjo6O59Z57Eccd3Pj4eJFIVF1dPWprZGSkXC4f73/RTCZTfX09AKhUqj179syZM6e+vn5iXT2n8+fPE0KSk5O5RYlE8rT3ZR/kieL/85//BAYGAsDVq1cHBgY2b96s0Wjkcvmwa6ChoaErVqw4duxYYWHhD3/4Q+d6z72I4w6uSqXKzMysrKwsLy+3Wq1XrlwpLS11tsrl8vXr11dUVJSUlFitVofD0dHRcffuXfd9mkymTZs2NTQ09Pf319XVtbe3JycnT6yrCRgaGrJYLIODg1euXNmyZUtUVFR2djbXNGPGjIcPHx47dmxgYKCrq6u9vd31FydPnmwymdra2h49eiRUvj1X/MDAwL17986fP88FNyoqCgC+/PLLx48f37x503ndzen999/v6+s7deqU679+PPgiup7Dx3g57NGjRzk5OWFhYUFBQampqXl5eQCgVqsvX75MCOnr69Pr9VFRURKJhEv59evXi4uLWZYFgJkzZ7a0tJSWliqVSgCIjo5uampqa2tLSUkJDQ0Vi8VTp07Nzc3l/iYdtSv3te3fv5+7eMmy7DvvvON+XELIxo0bAwICXnnlFYlEolQq33333ZaWFmdvDx48+Pa3vy2Xy6dPn/6Tn/yEu2I9Y8YM7pLTf//73+joaIVCkZqa2tnZ6aaqsVxVqK2tjYuLE4lEABAREbF7926vFf+73/0uJibmaQn54osvuA71ev3kyZMnTZq0bNky7jJ5TEyM8+obIeSb3/zmz3/+82H7NeqLmJ+fr1AoACAyMvJPf/qT+yNDeLkc5mc2btw4efJkT48y9sth4+Kd4sfu+9//fmtrqyd6HhlcP/yswnhx13QoJXjxzmnGlStXuLO7d8alLLgNDQ3M0+l0OqELfOHo9fqbN282NTWtX7/+l7/8pdfGpSy4sbGxbt5QDh8+PK7etm/ffujQoe7u7unTp1P3YGAfKZ5l2djY2Lfffnvnzp2zZ8/22rgMcfn0qtFoXLFiBaHz86y+DJ+P+5wYhjEYDMuXL3euoeyMixAHg4uohMFFVMLgIiphcBGVMLiIShhcRCUMLqISBhdRCYOLqITBRVTC4CIqYXARlUZ5WiP3USbEo9raWsADy6snghsZGanVaoUqxc9cvHgRAObOnQsAzjtv0cRotdrIyEjXNQx++tZDuA+PGo1GoQvxTzjHRVTC4CIqYXARlTC4iEoYXEQlDC6iEgYXUQmDi6iEwUVUwuAiKmFwEZUwuIhKGFxEJQwuohIGF1EJg4uohMFFVMLgIiphcBGVMLiIShhcRCUMLqISBhdRCYOLqITBRVTC4CIqYXARlTC4iEoYXEQlDC6iEgYXUQmDi6iEwUVUwieS8+YPf/jDvn37HA4Ht9jV1QUAKpWKWxSLxVu2bMnOzhaqPD+DweVNY2NjbGysmw1u3LjhfgM0djhV4M2sWbMSEhIYhhnZxDBMQkICppZHGFw+rV27ViwWj1wvkUjWrVvn/Xr8GE4V+GQymdRq9chDyjDMrVu31Gq1IFX5JTzj8mnq1KkpKSki0RNHVSQSpaSkYGr5hcHl2Zo1a4ZNcxmGWbt2rVD1+CucKvDs4cOHU6ZMGRwcdK4Ri8X37t0LCwsTsCr/g2dcnk2ePDk9PV0i+f/vmhWLxenp6Zha3mFw+ZeVlTU0NMT9TAhZs2aNsPX4JZwq8K+3t/ell156/PgxAMhksvv37wcFBQldlL/BMy7/AgMD33nnnYCAAIlE8u6772JqPQGD6xGrV68eHBx0OByrVq0Suhb/JBG6gOGMRqPQJfDA4XDI5XJCSE9Pj3/s0fLly4Uu4Qk+N8cd9X/9SHC+lhNfnCoYDAZCM61Wq9Vqq6qq/vGPfwhdCw8MBoPQiRiFz00V/MZbb70ldAn+DIPrKcM+sYD4hQcXUQmDi6iEwUVUwuAiKmFwEZUwuIhKGFxEJQwuohIGF1EJg4uohMFFVMLgIipRH9ycnJzg4GCGYS5duiR0LeNw9OhRjUbDuJBKpeHh4WlpaQUFBRaLRegCfR31wS0rKzt48KDQVYxbZmZma2trTExMSEgIIWRoaMhsNhuNxunTp+v1+ri4uIsXLwpdo0+jPrj+gWGYSZMmpaWlHTp0yGg03rt3b/Hixd3d3ULX5bv8Ibh+drePVqvNzs42m80HDhwQuhbfRWVwCSEFBQWzZs2SyWQhISHbtm1zbXU4HHl5eVFRUQqFIjExkbvzpKSkJDAwkGXZ48ePZ2RkKJVKtVpdUVHh/K3q6uqkpCSWZZVKZUJCgtVqfVpXXsA9uPz06dN+s0f8E/qOpuFgDPec5ebmMgyzd+9ei8Vis9mKi4sBoK6ujmvdunWrTCarrKy0WCzbt28XiUQXLlzgfgsAzp07193dbTabFyxYEBgY2N/fTwjp6elRKpX5+fl2u72zs3Pp0qVdXV1uunKPu+dsLDvrnOMOw4UsMjLSF/aIC/dYdsebfK+gZwXXZrOxLJuenu5cw51muODa7XaWZXU6nXNjmUy2efNm8vXLbLfbuSYu7s3NzYSQa9euAcCpU6dcB3LTlXvPH1xCCDfr9YU98s3g0jdVaG5uttlsCxcuHLW1sbHRZrPFx8dziwqFIiIioqGhYeSWUqkUAAYGBgBAo9GEh4dnZWXt3Lmzra1tvF3xrre3lxCiVCrHVYYv7xHv6AtuR0cHuHybzTC9vb0AsGPHDuf10fb2dpvN5r5PhUJRVVWVmpq6e/dujUaj0+nsdvvEuuJFU1MTAHDfGeEfe8Q7+oIrl8sBoK+vb9RWLtBFRUWubys1NTXP7DYuLu7kyZMmk0mv1xsMhsLCwgl39fzOnDkDABkZGeAve8Q7+oIbHx8vEomqq6tHbY2MjJTL5eP9L5rJZKqvrwcAlUq1Z8+eOXPm1NfXT6yr59fZ2VlUVKRWqzds2AB+sUeeQF9wVSpVZmZmZWVleXm51Wq9cuVKaWmps1Uul69fv76ioqKkpMRqtTocjo6Ojrt377rv02Qybdq0qaGhob+/v66urr29PTk5eWJdjRchpKenZ2hoiBDS1dVlMBjmz58vFouPHTvGzXGp2yMv8dAffRMGY7gc9ujRo5ycnLCwsKCgoNTU1Ly8PABQq9WXL18mhPT19en1+qioKIlEwqX8+vXrxcXFLMsCwMyZM1taWkpLS7lYREdHNzU1tbW1paSkhIaGisXiqVOn5ubmDg4OPq2rZ+7CWK4qnDhxIjExkWVZqVTKPTqEu4yQlJS0a9euBw8euG4s7B755lUFX3zoncFg8LVnA47LsmXLAODIkSNCF8IPo9G4YsUKX8sJfVMFhACDiyiFwUVUwuAiKmFwEZUwuIhKGFxEJQwuohIGF1EJg4uohMFFVMLgIiphcBGVMLiIShhcRCUMLqISBhdRyRe/y5fS+06duBvojUaj0IXwwzdfDl+8dUfoEtAofC4nvlaQ3+Bum/Ob866vwTkuohIGF1EJg4uohMFFVMLgIiphcBGVMLiIShhcRCUMLqISBhdRCYOLqITBRVTC4CIqYXARlTC4iEoYXEQlDC6iEgYXUQmDi6iEwUVUwuAiKmFwEZUwuIhKGFxEJQwuohIGF1EJg4uohMFFVMLgIiphcBGVMLiIShhcRCUMLqKSL34HBKWqq6tra2udiw0NDQCQn5/vXJOcnPzWW28JUJk/wkfp8+bvf//7d7/73YCAAJFo+PvY0NDQwMDA3/72t/T0dEFq8z8YXN44HI4pU6Y8ePBg1NbQ0FCz2SyR4FscP3COyxuxWLx69WqpVDqySSqVrlmzBlPLIwwun1auXNnf3z9yfX9//8qVK71fjx/DqQLPoqOjb926NWylWq2+desWfoUbj/CMy7OsrKyAgADXNVKpdN26dZhafuEZl2c3btyYPXv2sJVXr16Nj48XpB5/hcHl3+zZs2/cuOFcjI2NdV1EvMCpAv/Wrl3rnC0EBASsW7dO2Hr8Ep5x+Xfr1q1p06ZxB5ZhmNbW1mnTpgldlL/BMy7/oqKi5s6dKxKJGIZ54403MLWegMH1iLVr14pEIrFYvGbNGqFr8U84VfCIrq6ul19+GQDu3LkzZcoUocvxQwIEF69o+h/vp0iY/55v2bJl3rx5ggztNdXV1QzDvPnmm8PWFxUVAcCHH34oRFH8q6mp2bdvn/fHFSa48+bNW758uSBDe82iRYsAQKlUDlt/5MgRAPCn3X+BgvsiGBlZxCO8qoCohMFFVMLgIiphcBGVMLiIShhcRCUMLqISBhdRCYOLqITBRVTC4CIqYXARlTC4iEoUBDcnJyc4OJhhmEuXLgldyxOGhoaKiopSUlJ47/no0aMajYZxIZVKw8PD09LSCgoKLBYL7yNSh4LglpWVHTx4UOgqhrt58+abb7750Ucf2Ww23jvPzMxsbW2NiYkJCQkhhAwNDZnNZqPROH36dL1eHxcXd/HiRd4HpQsFwfVBly9f/tnPfvb+++9/4xvf8MJwDMNMmjQpLS3t0KFDRqPx3r17ixcv7u7u9sLQPouO4PrabWqvv/760aNHV69eLZPJvDy0VqvNzs42m80HDhzw8tA+xUeDSwgpKCiYNWuWTCYLCQnZtm2ba6vD4cjLy4uKilIoFImJiQaDAQBKSkoCAwNZlj1+/HhGRoZSqVSr1RUVFc7fqq6uTkpKYllWqVQmJCRYrdandeXjsrOzAeD06dPc4gt6NIjXAYDBYHC/TW5uLsMwe/futVgsNputuLgYAOrq6rjWrVu3ymSyyspKi8Wyfft2kUh04cIF7rcA4Ny5c93d3WazecGCBYGBgf39/YSQnp4epVKZn59vt9s7OzuXLl3a1dXlpqsx+ta3vvX666+Pa/e1Wq1Wqx3Lls457jBcyCIjI7lFYY8GF+5xHQFe+GJwbTYby7Lp6enONdypgguu3W5nWVan0zk3lslkmzdvJl+/VHa7nWvi4t7c3EwIuXbtGgCcOnXKdSA3XY2RIMElhHCzXuIDR0Oo4PriVKG5udlmsy1cuHDU1sbGRpvN5nxqp0KhiIiI4L7iZhjuqfYDAwMAoNFowsPDs7Kydu7c2dbWNt6ufEpvby8hhLsZ84U9Gr4Y3I6ODgBQqVSjtvb29gLAjh07nNc429vbn3lNSqFQVFVVpaam7t69W6PR6HQ6u90+sa4E19TUBACxsbHwAh8NXwyuXC4HgL6+vlFbuUAXFRW5vnHU1NQ8s9u4uLiTJ0+aTCa9Xm8wGAoLCyfclbDOnDkDABkZGfACHw1fDG58fLxIJKqurh61NTIyUi6Xj/e/aCaTqb6+HgBUKtWePXvmzJlTX18/sa6E1dnZWVRUpFarN2zYAC/w0fDF4KpUqszMzMrKyvLycqvVeuXKldLSUmerXC5fv359RUVFSUmJ1Wp1OBwdHR13795136fJZNq0aVNDQ0N/f39dXV17e3tycvLEuvImQkhPT8/Q0BAhpKury2AwzJ8/XywWHzt2jJvjvlBH4wke+qPPDRjD5bBHjx7l5OSEhYUFBQWlpqbm5eUBgFqtvnz5MiGkr69Pr9dHRUVJJBIu5devXy8uLmZZFgBmzpzZ0tJSWlrKvbTR0dFNTU1tbW0pKSmhoaFisXjq1Km5ubmDg4NP6+qZu1BTUzN//nzueYwAEBERkZKSUl1dPZbdH8tVhRMnTiQmJrIsK5VKue+p5C4jJCUl7dq168GDB64bC3s0hLqqIMzTGg0Ggz89PGtcli1bBl8/QcwPGI3GFStWeD9FvjhVQOiZMLjDNTQ0ME+n0+mELhAB4NMaR4qNjfX+Gx8aLzzjIiphcBGVMLiIShhcRCUMLqISBhdRCYOLqITBRVTC4CIqYXARlTC4iEoYXEQlDC6iEgYXUUmYOyC8PCLyNO+nSIDP4/r0E6n4U1RUBAAffvih0IX4JwHOuC8I7qY6o9EodCH+Cee4iEoYXEQlDC6iEgYXUQmDi6iEwUVUwuAiKmFwEZUwuIhKGFxEJQwuohIGF1EJg4uohMFFVMLgIiphcBGVMLiIShhcRCUMLqISBhdRCYOLqITBRVTC4CIqYXARlTC4iEoYXEQlDC6iEgYXUQmDi6iEwUVUwuAiKmFwEZUEeCK5v7p//77VanUu9vb2AkBra6tzjVKpfOmllwSozB/hE8l5U15enpOT42aDsrKy9957z2v1+DcMLm8sFsuUKVMGBgZGbQ0ICLh3715oaKiXq/JXOMflTWho6KJFiySSUWZfEokkIyMDU8sjDC6fsrKyHA7HyPUOhyMrK8v79fgxnCrw6fHjx2FhYTabbdh6hUJx//59lmUFqcov4RmXT3K5fMmSJQEBAa4rAwICMjMzMbX8wuDybNWqVcP+PhsYGFi1apVQ9fgrnCrwbHBwMDw83GKxONdMmjTJbDYPOw2j54RnXJ5JJBKdTieVSrnFgICAVatWYWp5h8Hl38qVK/v7+7mfBwYGVq5cKWw9fgmnCvwjhKjVapPJBAAREREmkwm/MJ53eMblH8MwWVlZUqk0ICBg7dq1mFpPwOB6BDdbwOsJniPAp8OWLVvm/UG9LygoCAA+/fRToQvxhiNHjnh5RAHmuAzDJCcnq9VqL4/rZTdu3ACA1157bdj62tpaAEhOThagJg/o6Oiora0VIEWCBNdgMCxfvtzL43pZS0sLAMTExAxbz73heP8U5SFGo3HFihXeTxF+kNxTRkYW8Qj/OENUwuAiKmFwEZUwuIhKGFxEJQwuohIGF1EJg4uohMFFVMLgIiphcBGVMLiIShhcRCUKgpuTkxMcHMwwzKVLl4Su5f/t2rVr9uzZSqVSJpPNmDHjk08+6enp4bH/o0ePajQaxoVUKg0PD09LSysoKHC99/2FRUFwy8rKDh48KHQVT6iqqvrxj3/c1tZ2//79zz77bN++ffze1pGZmdna2hoTExMSEkIIGRoaMpvNRqNx+vTper0+Li7u4sWLPA5HIwqC64OCgoI2btw4efLk4ODg5cuXL1my5MyZM7dv3/bQcAzDTJo0KS0t7dChQ0aj8d69e4sXL+7u7vbQcFSgI7i+dqPsqVOnxGKxc5F7zvjIZ915glarzc7ONpvNBw4c8MJwPstHg0sIKSgomDVrlkwmCwkJ2bZtm2urw+HIy8uLiopSKBSJiYkGgwEASkpKAgMDWZY9fvx4RkaGUqlUq9UVFRXO36qurk5KSmJZVqlUJiQkcI+9H7Wr8bpz545CoZg+ffrz7fRYZWdnA8Dp06e5RV87Gl5CvA4ADAaD+21yc3MZhtm7d6/FYrHZbMXFxQBQV1fHtW7dulUmk1VWVloslu3bt4tEogsXLnC/BQDnzp3r7u42m80LFiwIDAzs7+8nhPT09CiVyvz8fLvd3tnZuXTp0q6uLjddjV1vb29wcPAHH3wwxu21Wq1Wqx3Lls457jBcyCIjI7lFYY8GF+4x7juPfDG4NpuNZdn09HTnGu5UwQXXbrezLKvT6Zwby2SyzZs3k69fKrvdzjVxcW9ubiaEXLt2DQBOnTrlOpCbrsYuNzf31VdftVqtY9z++YNLCOFmvcQHjoZQwfXFqUJzc7PNZlu4cOGorY2NjTabLT4+nltUKBQRERENDQ0jt+SePMc99FOj0YSHh2dlZe3cubOtrW28XT3NF198YTQaz549GxwcPPbfek69vb2EEKVSCT52NLzJF4Pb0dEBACqVatRW7muYduzY4bzG2d7e/sw/jBQKRVVVVWpq6u7duzUajU6ns9vtE+vK6fDhw7/61a/Onz8/bdq0se/d82tqagKA2NhY8KWj4WW+GFy5XA4AfX19o7ZygS4qKnJ946ipqXlmt3FxcSdPnjSZTHq93mAwFBYWTrgrANi/f/+f//znqqqqqVOnjmPf+HDmzBkAyMjIAJ85Gt7ni8GNj48XiUTV1dWjtkZGRsrl8vH+F81kMtXX1wOASqXas2fPnDlz6uvrJ9YVIUSv11+9evXYsWPcc5a8qbOzs6ioSK1Wb9iwAXzgaAjFF4OrUqkyMzMrKyvLy8utVuuVK1dKS0udrXK5fP369RUVFSUlJVar1eFwdHR03L17132fJpNp06ZNDQ0N/f39dXV17e3tycnJE+uqvr7+888/P3jwYEBAgOt/ZQsLC3nY+ScRQnp6eoaGhgghXV1dBoNh/vz5YrH42LFj3BxX8KMhGM/8zecOjOFy2KNHj3JycsLCwoKCglJTU/Py8gBArVZfvnyZENLX16fX66OioiQSCZfy69evFxcXc18QMnPmzJaWltLSUu6ljY6ObmpqamtrS0lJCQ0NFYvFU6dOzc3NHRwcfFpX7mu7evXqqEeyoKBgLLs/lqsKJ06cSExMZFlWKpWKRCL4+p9nSUlJu3btevDggevGwh4Noa4q4LPDvA2fHcYLX5wqIPRMGNzhGhoamKfT6XRCF4gA8GmNI8XGxnr/jQ+NF55xEZUwuIhKGFxEJQwuohIGF1EJg4uohMFFVMLgIiphcBGVMLiIShhcRCUMLqISBhdRCYOLqCTMHRDJyclqtdrL4/qI2tpaAEhOTha6EH50dHTU1tYKkCLvD8nvEzmRL/D+nUgCBBeh54dzXEQlDC6iEgYXUQmDi6j0fwnkuTi7Ukb4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVvUxpAkOQuz",
        "outputId": "0bd454c7-a8be-4c13-b62c-f5367b91a61e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history =network.fit(train_images, train_labels, validation_split=0.33,epochs=24, batch_size=32)\n",
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/24\n",
            "1257/1257 [==============================] - 7s 6ms/step - loss: 0.0226 - accuracy: 0.9930 - val_loss: 0.0281 - val_accuracy: 0.9911\n",
            "Epoch 2/24\n",
            " 823/1257 [==================>...........] - ETA: 1s - loss: 0.0185 - accuracy: 0.9952"
          ]
        }
      ]
    }
  ]
}